eval_config:
  tasks:
    leaderboard_musr:
      num_fewshot: null

    leaderboard_bbh:
      num_fewshot: null

    leaderboard_mmlu_pro:
      num_fewshot: 5

    leaderboard_gpqa:
      num_fewshot: null

    leaderboard_ifeval:
      num_fewshot: null

train_config:
  batch_size: 1
  lr: 0.00001
  max_seq_length: 4096
  max_steps: 1000
  warmup_steps: 100
  weight_decay: 0.01
  epochs: 1

  datasets:
    - name: "nickrosh/Evol-Instruct-Code-80k-v1"
      num_samples: 1000

run_name: "train-test"
run_initial_eval: false

student_model: "deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B"
teacher_model: "deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B" #TODO: change to 7B after debugging
