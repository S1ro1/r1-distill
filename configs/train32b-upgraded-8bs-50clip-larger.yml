eval_config:
  tasks:
    leaderboard_musr:
      num_fewshot: null

    leaderboard_bbh:
      num_fewshot: null

    leaderboard_mmlu_pro:
      num_fewshot: 5

    leaderboard_gpqa:
      num_fewshot: null

    leaderboard_ifeval:
      num_fewshot: null

train_config:
  batch_size: 1
  lr: 0.0001
  max_seq_length: 4096
  warmup_ratio: 0.1
  weight_decay: 0.01
  epochs: 1
  gradient_accumulation_steps: 8
  kl_clip: 50.0

  gradient_checkpointing: true
  gradient_checkpointing_kwargs:
    use_reentrant: false

  datasets:
    - name: "nickrosh/Evol-Instruct-Code-80k-v1"
      num_samples: 12000
    - name: "microsoft/orca-math-word-problems-200k"
      num_samples: 12000
    - name: "meta-math/MetaMathQA"
      num_samples: 12000

run_name: "Qwen-1.5B-by-32B-4096-upgraded-8bs-50clip-larger"
model_name: "Qwen-1.5B-redistill-32B-36k-upgraded-8bs-50clip-larger"
teacher_in_8bit: "hqq"

run_initial_eval: false
run_training: true
run_final_eval: true
save_steps: 15000

student_model: "deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B"
teacher_model: "deepseek-ai/DeepSeek-R1-Distill-Qwen-32B"
